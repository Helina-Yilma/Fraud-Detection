{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6aa988f",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2bbfe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b729dfe",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e29381dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "fraud_data = pd.read_csv('../data/processed/fraud_data_cleaned.csv')\n",
    "ip_country = pd.read_csv('../data/raw/IpAddress_to_Country.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca82985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 138846 entries, 0 to 138845\n",
      "Data columns (total 3 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   lower_bound_ip_address  138846 non-null  float64\n",
      " 1   upper_bound_ip_address  138846 non-null  int64  \n",
      " 2   country                 138846 non-null  object \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "ip_country.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f723749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure IP addresses are integer for comparison\n",
    "fraud_data['ip_address'] = fraud_data['ip_address'].astype(int)\n",
    "ip_country['lower_bound_ip_address'] = ip_country['lower_bound_ip_address'].astype(int)\n",
    "ip_country['upper_bound_ip_address'] = ip_country['upper_bound_ip_address'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2268a1",
   "metadata": {},
   "source": [
    "### Geolocation Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e6aba",
   "metadata": {},
   "source": [
    "#### Merge Fraud_Data.csv with IpAddress_to_Country.csv using range-based lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69fb8da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort both dataframes by the IP columns (required for merge_asof)\n",
    "fraud_data = fraud_data.sort_values('ip_address')\n",
    "ip_country = ip_country.sort_values('lower_bound_ip_address')\n",
    "\n",
    "# Use merge_asof to find the closest lower bound\n",
    "fraud_data_merged = pd.merge_asof(\n",
    "    fraud_data, \n",
    "    ip_country, \n",
    "    left_on='ip_address', \n",
    "    right_on='lower_bound_ip_address'\n",
    ")\n",
    "\n",
    "# Validate that the ip_address actually falls within the range [lower, upper]\n",
    "# If it's outside the range, set the country to 'Unknown'\n",
    "fraud_data_merged['country'] = np.where(\n",
    "    (fraud_data_merged['ip_address'] >= fraud_data_merged['lower_bound_ip_address']) & \n",
    "    (fraud_data_merged['ip_address'] <= fraud_data_merged['upper_bound_ip_address']),\n",
    "    fraud_data_merged['country'],\n",
    "    'Unknown'\n",
    ")\n",
    "\n",
    "# Clean up temporary lookup columns\n",
    "fraud_data_merged = fraud_data_merged.drop(['lower_bound_ip_address', 'upper_bound_ip_address'], axis=1)\n",
    "\n",
    "# Save to processed folder\n",
    "import os\n",
    "fraud_data_merged.to_csv('../data/processed/fraud_data_with_country.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c510d18",
   "metadata": {},
   "source": [
    "#### Analyze Fraud Patterns by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c80ce97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Countries by Volume:\n",
      "country\n",
      "United States        58049\n",
      "Unknown              21966\n",
      "China                12038\n",
      "Japan                 7306\n",
      "United Kingdom        4490\n",
      "Korea Republic of     4162\n",
      "Germany               3646\n",
      "France                3161\n",
      "Canada                2975\n",
      "Brazil                2961\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 10 Countries with most Fraudulent Transactions:\n",
      "country\n",
      "United States        5551\n",
      "Unknown              1883\n",
      "China                1043\n",
      "Japan                 715\n",
      "United Kingdom        477\n",
      "Korea Republic of     380\n",
      "Canada                348\n",
      "France                300\n",
      "Brazil                270\n",
      "Germany               262\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Countries with Highest Fraud Rates (>50 transactions):\n",
      "              total_transactions  fraud_rate\n",
      "country                                     \n",
      "Luxembourg                    72   38.888889\n",
      "Ecuador                      106   26.415094\n",
      "Tunisia                      118   26.271186\n",
      "Peru                         119   26.050420\n",
      "Bolivia                       53   24.528302\n",
      "Kuwait                        90   23.333333\n",
      "Ireland                      240   22.916667\n",
      "New Zealand                  278   22.302158\n",
      "Lithuania                     95   18.947368\n",
      "Saudi Arabia                 264   18.939394\n"
     ]
    }
   ],
   "source": [
    "# 1. Top 10 Countries by Total Transactions\n",
    "print(\"Top 10 Countries by Volume:\")\n",
    "print(fraud_data_merged['country'].value_counts().head(10))\n",
    "\n",
    "# 2. Top 10 Countries by Fraud Count\n",
    "fraud_counts = fraud_data_merged[fraud_data_merged['class'] == 1]['country'].value_counts()\n",
    "print(\"\\nTop 10 Countries with most Fraudulent Transactions:\")\n",
    "print(fraud_counts.head(10))\n",
    "\n",
    "# 3. Fraud Rate by Country (Percentage of transactions that are fraud)\n",
    "country_stats = fraud_data_merged.groupby('country').agg(\n",
    "    total_transactions=('class', 'count'),\n",
    "    fraud_cases=('class', 'sum')\n",
    ")\n",
    "country_stats['fraud_rate'] = (country_stats['fraud_cases'] / country_stats['total_transactions']) * 100\n",
    "\n",
    "# Filter for countries with a significant sample size (e.g., > 50 transactions)\n",
    "high_risk_countries = country_stats[country_stats['total_transactions'] > 50].sort_values(by='fraud_rate', ascending=False)\n",
    "\n",
    "print(\"\\nCountries with Highest Fraud Rates (>50 transactions):\")\n",
    "print(high_risk_countries[['total_transactions', 'fraud_rate']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b1b6d5",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db5688f",
   "metadata": {},
   "source": [
    "#### Time Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bf3e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'purchase_time' and 'signup_time' are already datetime objects\n",
    "# 1. Extract cyclic time features\n",
    "fraud_df = fraud_data_merged\n",
    "fraud_df['signup_time'] = pd.to_datetime(fraud_df['signup_time'])\n",
    "fraud_df['purchase_time'] = pd.to_datetime(fraud_df['purchase_time'])\n",
    "fraud_df['hour_of_day'] = fraud_df['purchase_time'].dt.hour\n",
    "fraud_df['day_of_week'] = fraud_df['purchase_time'].dt.dayofweek\n",
    "\n",
    "# 2. Time since signup (in seconds)\n",
    "# Fraudsters often create an account and make a purchase immediately.\n",
    "fraud_df['time_since_signup'] = (fraud_df['purchase_time'] - fraud_df['signup_time']).dt.total_seconds()\n",
    "\n",
    "# Convert to hours or days if the numbers are too large for your model\n",
    "fraud_df['time_since_signup_h'] = fraud_df['time_since_signup'] / 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2fbd97",
   "metadata": {},
   "source": [
    "#### Transaction frequency and velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6a74cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_10852\\1124936853.py:20: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  .rolling('24H')\n"
     ]
    }
   ],
   "source": [
    "# 1. Frequency per Device\n",
    "# Count how many times each device_id appears in the entire dataset\n",
    "fraud_df['device_id_count'] = fraud_df.groupby('device_id')['device_id'].transform('count')\n",
    "\n",
    "# 2. Frequency per IP Address\n",
    "# Similar to device, multiple users on one IP can indicate a botnet or proxy\n",
    "fraud_df['ip_address_count'] = fraud_df.groupby('ip_address')['ip_address'].transform('count')\n",
    "\n",
    "# 3. Rolling Window Velocity (Advanced)\n",
    "# 1. Sort by user and time\n",
    "fraud_df = fraud_df.sort_values(by=['user_id', 'purchase_time'])\n",
    "\n",
    "# 2. Set purchase_time as index to allow time-based rolling windows\n",
    "fraud_df = fraud_df.set_index('purchase_time')\n",
    "\n",
    "# 3. Calculate velocity (transactions per user in the last 24 hours)\n",
    "# We group by user_id and then use a 24-hour rolling window\n",
    "fraud_df['user_transaction_velocity'] = (\n",
    "    fraud_df.groupby('user_id')['user_id']\n",
    "    .rolling('24H')\n",
    "    .count()\n",
    "    .reset_index(level=0, drop=True) # Removes the extra 'user_id' index level created by groupby\n",
    ")\n",
    "\n",
    "# 4. Reset index if you want purchase_time back as a column\n",
    "fraud_df = fraud_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "174bad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# 1. Scale Numerical Features\n",
    "# Features like 'time_since_signup' have huge ranges, while 'age' is small.\n",
    "scaler = StandardScaler()\n",
    "num_features = ['purchase_value', 'age', 'time_since_signup', 'device_id_count', 'ip_address_count']\n",
    "fraud_df[num_features] = scaler.fit_transform(fraud_df[num_features])\n",
    "\n",
    "# 2. One-Hot Encoding for Categorical Features\n",
    "# Convert Browser, Source, and Sex into binary columns\n",
    "fraud_df = pd.get_dummies(fraud_df, columns=['source', 'browser', 'sex'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c20c4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: class\n",
      "0    109568\n",
      "1     11321\n",
      "Name: count, dtype: int64\n",
      "After SMOTE: class\n",
      "0    109568\n",
      "1    109568\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define Features (X) and Target (y)\n",
    "X = fraud_df.drop(['class', 'user_id', 'device_id', 'signup_time', 'purchase_time', 'ip_address', 'country'], axis=1)\n",
    "y = fraud_df['class']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to training data only\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Before SMOTE: {y_train.value_counts()}\")\n",
    "print(f\"After SMOTE: {y_train_res.value_counts()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
